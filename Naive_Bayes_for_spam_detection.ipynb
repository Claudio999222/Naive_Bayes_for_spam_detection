{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ece99722-4d31-4927-92f5-21b6fe9c0145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn import naive_bayes, metrics\n",
    "from sklearn import preprocessing\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73753d13-adea-4176-ae97-5c52a7a0a8a6",
   "metadata": {},
   "source": [
    "#### Importo il dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97af4116-fd17-4ffb-ac17-9421db7f9669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        SMS\n",
      "Label      \n",
      "ham    4825\n",
      "spam    747\n"
     ]
    }
   ],
   "source": [
    "sms_data = pd.read_csv(r'C:\\Users\\claud\\Desktop\\Project\\MASTER CLASS MACHINE LEARNING\\moduli\\6 - Algoritmi Machine Learning\\Esercitazioni 6 modulo\\datasets\\SMSSpamCollection',\n",
    "                      header = None,\n",
    "                      sep = '\\t',\n",
    "                      names = ['Label', 'SMS'])\n",
    "\n",
    "print(sms_data.groupby('Label').count())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f1a847-d83f-4b40-8e0c-e4571393ac0c",
   "metadata": {},
   "source": [
    "#### Visualizzo le prime 5 righe del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69be2161-3d31-460e-ba07-8c9cdb6068a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham\n",
      "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "\n",
      "\n",
      "ham\n",
      "Ok lar... Joking wif u oni...\n",
      "\n",
      "\n",
      "spam\n",
      "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "\n",
      "\n",
      "ham\n",
      "U dun say so early hor... U c already then say...\n",
      "\n",
      "\n",
      "ham\n",
      "Nah I don't think he goes to usf, he lives around here though\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 5):\n",
    "    print(sms_data['Label'][i])\n",
    "    print(sms_data['SMS'][i])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aed32f-0918-4d3b-b5e3-96dea59ac0b7",
   "metadata": {},
   "source": [
    "#### Effettuo una pulizia del testo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea406d73-3a06-4854-af62-52380ed3e6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_data_clean = sms_data.copy()\n",
    "sms_data_clean['SMS'] = sms_data_clean['SMS'].str.replace(r'\\W+', ' ', regex=True).str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "sms_data_clean['SMS'] = sms_data_clean['SMS'].str.lower()\n",
    "sms_data_clean['SMS'] = sms_data_clean['SMS'].str.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7afbc9c-f310-45f7-9622-1c350d221c59",
   "metadata": {},
   "source": [
    "#### Codifico le etichette con LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f156cacb-c123-4fef-a73c-e3cb555e0821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['go', 'until', 'jurong', 'point', 'crazy', 'available', 'only', 'in', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet', 'cine', 'there', 'got', 'amore', 'wat']\n",
      "\n",
      "\n",
      "0\n",
      "['ok', 'lar', 'joking', 'wif', 'u', 'oni']\n",
      "\n",
      "\n",
      "1\n",
      "['free', 'entry', 'in', '2', 'a', 'wkly', 'comp', 'to', 'win', 'fa', 'cup', 'final', 'tkts', '21st', 'may', '2005', 'text', 'fa', 'to', '87121', 'to', 'receive', 'entry', 'question', 'std', 'txt', 'rate', 't', 'c', 's', 'apply', '08452810075over18', 's']\n",
      "\n",
      "\n",
      "0\n",
      "['u', 'dun', 'say', 'so', 'early', 'hor', 'u', 'c', 'already', 'then', 'say']\n",
      "\n",
      "\n",
      "0\n",
      "['nah', 'i', 'don', 't', 'think', 'he', 'goes', 'to', 'usf', 'he', 'lives', 'around', 'here', 'though']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "sms_data_clean['Label'] = le.fit_transform(sms_data_clean['Label'])\n",
    "\n",
    "for i in range(0, 5):\n",
    "    print(sms_data_clean['Label'][i])\n",
    "    print(sms_data_clean['SMS'][i])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252fd557-d6f8-42d3-ab43-50c630c1b154",
   "metadata": {},
   "source": [
    "#### Divido il dataset in train e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca7fb5a0-3a68-4843-bd97-a1ea7de7f68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(sms_data_clean['SMS'], sms_data_clean['Label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c6afb3-8c1a-43f0-a04c-e0ce078e93f3",
   "metadata": {},
   "source": [
    "#### Conteggio di quanti sono i 0 e 1 (ham & spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed6c81a0-86bb-4bc6-b0df-4584e816702c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    4825\n",
       "1     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_data_clean['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442e9b41-fda3-4478-a535-1e52335c55c0",
   "metadata": {},
   "source": [
    "#### Percentuale di quanti sono i 0 e 1 (ham & spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "791da761-4819-4e8d-9260-87b6abe1fb86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    86.593683\n",
       "1    13.406317\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_data_clean['Label'].value_counts() / sms_data.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4134f01c-ed5a-4881-b207-812dcdc3c40a",
   "metadata": {},
   "source": [
    "#### Creo un nuovo dataset dove le colonne sono le parole presenti nel dataset e vengono conteggiate quante volte le parole sono presenti in ogni riga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1ef00f0-7a18-4bf8-a378-9da4078378af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sounds</th>\n",
       "      <th>set</th>\n",
       "      <th>dogging</th>\n",
       "      <th>s</th>\n",
       "      <th>84128</th>\n",
       "      <th>80086</th>\n",
       "      <th>dressed</th>\n",
       "      <th>g2</th>\n",
       "      <th>edison</th>\n",
       "      <th>turns</th>\n",
       "      <th>...</th>\n",
       "      <th>stressed</th>\n",
       "      <th>annoncement</th>\n",
       "      <th>station</th>\n",
       "      <th>evil</th>\n",
       "      <th>frosty</th>\n",
       "      <th>yalrigu</th>\n",
       "      <th>forgive</th>\n",
       "      <th>couple</th>\n",
       "      <th>d3wv</th>\n",
       "      <th>pleassssssseeeeee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7741 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sounds  set  dogging  s  84128  80086  dressed  g2  edison  turns  ...  \\\n",
       "0       0    0        0  0      0      0        0   0       0      0  ...   \n",
       "1       0    0        0  0      0      0        0   0       0      0  ...   \n",
       "2       0    0        0  0      0      0        0   0       0      0  ...   \n",
       "3       0    0        0  0      0      0        0   0       0      0  ...   \n",
       "4       0    0        0  0      0      0        0   0       0      0  ...   \n",
       "\n",
       "   stressed  annoncement  station  evil  frosty  yalrigu  forgive  couple  \\\n",
       "0         0            0        0     0       0        0        0       0   \n",
       "1         0            0        0     0       0        0        0       0   \n",
       "2         0            0        0     0       0        0        0       0   \n",
       "3         0            0        0     0       0        0        0       0   \n",
       "4         0            0        0     0       0        0        0       0   \n",
       "\n",
       "   d3wv  pleassssssseeeeee  \n",
       "0     0                  0  \n",
       "1     0                  0  \n",
       "2     0                  0  \n",
       "3     0                  0  \n",
       "4     0                  0  \n",
       "\n",
       "[5 rows x 7741 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = list(set(X_train.sum()))\n",
    "X_train_voc = pd.DataFrame([\n",
    "    [row.count(word) for word in vocabulary]\n",
    "    for row in X_train], columns=vocabulary)\n",
    "X_test_voc = pd.DataFrame([\n",
    "    [row.count(word) for word in vocabulary]\n",
    "    for row in X_test], columns=vocabulary)\n",
    "\n",
    "X_train_voc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6998918-38c3-4561-9c47-cc0c7dfc189f",
   "metadata": {},
   "source": [
    "#### Dimensioni del Train e del Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22339f37-d1c1-40ae-8aa4-a946a6f83c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4457, 7741)\n",
      "(1115, 7741)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_voc.shape)\n",
    "print(X_test_voc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0998010-7bd3-469d-af8c-91452c09eef7",
   "metadata": {},
   "source": [
    "#### Addestro un modello di Guassian Naive Bayes e ne misuro la percentuale di accuratezza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bafe0b9e-10e5-4bd5-859b-726ce7b76f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.03139013452915\n"
     ]
    }
   ],
   "source": [
    "cl_gauss = naive_bayes.GaussianNB()\n",
    "res_gauss = cl_gauss.fit(X_train_voc, y_train).predict(X_test_voc)\n",
    "print(metrics.accuracy_score(y_test, res_gauss) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a0bf93-c9aa-4497-86fd-af97ecaa5157",
   "metadata": {},
   "source": [
    "#### Addestro un modello di Multinomial Naive Bayes e ne misuro la percentuale di accuratezza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92e124ef-3140-4354-b4b4-502327acbf4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.19282511210761"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_multi = sklearn.naive_bayes.MultinomialNB()\n",
    "res_multi = cl_multi.fit(X_train_voc, y_train).predict(X_test_voc)\n",
    "metrics.accuracy_score(y_test, res_multi) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0a7ac9-0f1a-47a1-b593-f829f9aca63a",
   "metadata": {},
   "source": [
    "#### Addestro un modello di Bernoulli Naive Bayes e ne misuro la percentuale di accuratezza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d00422a5-b0e9-4b83-b407-a8f2c458f35e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.29596412556054"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_bern = sklearn.naive_bayes.BernoulliNB()\n",
    "res_bern = cl_bern.fit(X_train_voc, y_train).predict(X_test_voc)\n",
    "metrics.accuracy_score(y_test, res_bern) * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
